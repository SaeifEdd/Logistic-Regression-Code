{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52151efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22672038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Regression_FS:\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "        \n",
    "    def LR_fit(self, x, y, epochs):\n",
    "        x, y = self.transform (x, y)\n",
    "        \n",
    "        self.weights = np.random.normal(0, 1, size = x.shape[1])\n",
    "        self.b = 0\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            y_hat = self.sigmoid(np.matmul(self.weights, x.transpose()) + self.b)\n",
    "            dw, db = self.gradients(x, y_hat, y)\n",
    "            self.update_weights(dw, db)\n",
    "            \n",
    "            bce = self.binary_cross_enth(y_hat, y)\n",
    "            acc = self.cal_accuracy(y, y_hat)\n",
    "            \n",
    "            self.losses.append(bce)\n",
    "            self.accuracies.append(acc)\n",
    "        \n",
    "            \n",
    "        \n",
    "    def sigmoid(self, pred):\n",
    "        return np.array([self.sigmoid_exp(z) for z in pred])\n",
    "    \n",
    "    def sigmoid_exp(self, z):\n",
    "        if z >= 0:\n",
    "            return 1/(1+np.exp(-z))\n",
    "        else:\n",
    "            return np.exp(z)/(1+np.exp(z))\n",
    "    \n",
    "    \n",
    "    def binary_cross_enth(self, y_pred, y_true):\n",
    "        f = y_true * np.log(y_pred + 1e-9)\n",
    "        s = (1-y_true) * np.log(1 - y_pred + 1e-9)\n",
    "        return -np.mean(f + s)\n",
    "    \n",
    "    \n",
    "    def gradients(self, x, y_pred, y_true):\n",
    "        diff = y_pred - y_true\n",
    "        dw = 1/len(y_pred) * np.matmul(x.transpose() , diff)\n",
    "        db = np.mean(diff)\n",
    "        return dw, db\n",
    "    \n",
    "    \n",
    "    def update_weights(self, delta_w, delta_b):\n",
    "        self.weights -= 0.01*delta_w\n",
    "        self.b -= 0.01*delta_b\n",
    "        return \n",
    "    \n",
    "    def predict(self, x):\n",
    "        linear_y = np.matmul(self.weights, x.transpose()) + self.b\n",
    "        sig_y = self.sigmoid(linear_y)\n",
    "        return [1 if p > 0.5 else 0 for p in sig_y]\n",
    "    \n",
    "    \n",
    "    def cal_accuracy(self, y_true, y_pred):\n",
    "        tp_and_tn = np.sum(y_true == y_pred)\n",
    "        fp_and_fn = np.sum(y_true != y_pred)\n",
    "        return tp_and_tn / (tp_and_tn + fp_and_fn)\n",
    "    \n",
    "    \n",
    "    def transform(self, x, y):\n",
    "        x = copy.copy(x)\n",
    "        y = copy.copy(y)\n",
    "        return x.values, y.values\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08eb7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/ASUS/Downloads/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea87c58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5baffdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"target\"]\n",
    "x = data.drop(\"target\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc0d2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acca4325",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lr = Logistic_Regression_FS()\n",
    "my_lr.LR_fit(x_train, y_train, epochs = 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8c7a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0284d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1892855e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the class :  0.5409836065573771\n",
      "accuracy of python lr :  0.8852459016393442\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy of the class : \" , accuracy_score(my_lr.predict(x_test), y_test))\n",
    "print(\"accuracy of python lr : \", accuracy_score(lr.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875172c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
